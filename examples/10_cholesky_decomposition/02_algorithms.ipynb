{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640020d3",
   "metadata": {},
   "source": [
    "# ⚠️ Auto-generated Notebook\n",
    "    \n",
    "This notebook is automatically compiled from source files in `/workspaces/awesome-matrix/src/examples/10_cholesky_decomposition`.\n",
    "**Do not edit this file directly** as your changes will be overwritten.\n",
    "\n",
    "To make changes:\n",
    "1. Edit the source file `/workspaces/awesome-matrix/src/examples/10_cholesky_decomposition/02_algorithms.py` instead\n",
    "2. Run the compile script to regenerate this notebook\n",
    "\n",
    "See [COMPILE.md](docs/COMPILE.md) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df019170",
   "metadata": {},
   "source": [
    "# Cholesky Decomposition: Algorithms and Variants\n",
    "\n",
    "In this notebook, we explore various algorithms and variants of the Cholesky decomposition, including:\n",
    "\n",
    "1. Block Cholesky decomposition\n",
    "2. Modified Cholesky decomposition\n",
    "3. Incomplete Cholesky factorization\n",
    "4. Handling positive semi-definite matrices\n",
    "5. Rank-1 updates to Cholesky factors\n",
    "\n",
    "These variations are useful in different contexts and applications, such as optimization, solving linear systems efficiently, and handling ill-conditioned matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a006d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Set the default style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Helper function to create positive definite matrices\n",
    "def create_positive_definite_matrix(n, method=\"random\"):\n",
    "    \"\"\"Create a positive definite matrix of size n×n.\"\"\"\n",
    "    if method == \"random\":\n",
    "        # Create a random matrix\n",
    "        B = torch.randn(n, n)\n",
    "        # A = B*B^T is guaranteed to be positive definite (if B is full rank)\n",
    "        A = B @ B.T\n",
    "        # Add a small value to the diagonal to ensure positive definiteness\n",
    "        A = A + torch.eye(n) * 1e-5\n",
    "        return A\n",
    "    elif method == \"predetermined\":\n",
    "        # A predefined example\n",
    "        A = torch.tensor([[4.0, 1.0, 1.0], \n",
    "                           [1.0, 3.0, 2.0], \n",
    "                           [1.0, 2.0, 6.0]])\n",
    "        return A\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "\n",
    "# Helper function to visualize matrices\n",
    "def plot_matrix(matrix, title):\n",
    "    \"\"\"Plot a matrix as a heatmap with annotations.\"\"\"\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    \n",
    "    # Create heatmap\n",
    "    ax = sns.heatmap(matrix.numpy(), annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                    linewidths=.5, cbar=True)\n",
    "    \n",
    "    # Add column and row indices\n",
    "    ax.set_xticks(np.arange(matrix.shape[1]) + 0.5)\n",
    "    ax.set_yticks(np.arange(matrix.shape[0]) + 0.5)\n",
    "    ax.set_xticklabels(range(matrix.shape[1]))\n",
    "    ax.set_yticklabels(range(matrix.shape[0]))\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Column Index\")\n",
    "    plt.ylabel(\"Row Index\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b88cc",
   "metadata": {},
   "source": [
    "## 1. Block Cholesky Decomposition\n",
    "\n",
    "Block Cholesky decomposition is a variation of the standard algorithm that operates on blocks of the matrix rather than individual elements. This approach can be more efficient for large matrices, especially when combined with parallel computing.\n",
    "\n",
    "For a matrix $A$ partitioned into blocks:\n",
    "\n",
    "$$A = \\begin{bmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix}$$\n",
    "\n",
    "The block Cholesky decomposition gives:\n",
    "\n",
    "$$L = \\begin{bmatrix} L_{11} & 0 \\\\ L_{21} & L_{22} \\end{bmatrix}$$\n",
    "\n",
    "Where:\n",
    "- $L_{11}$ is the Cholesky factor of $A_{11}$\n",
    "- $L_{21} = A_{21} L_{11}^{-T}$\n",
    "- $L_{22}$ is the Cholesky factor of $A_{22} - L_{21}L_{21}^T$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_cholesky(A, block_size=2):\n",
    "    \"\"\"\n",
    "    Compute the Cholesky decomposition using a block algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        A (torch.Tensor): Positive definite matrix\n",
    "        block_size (int): Size of blocks to process\n",
    "        \n",
    "    Returns:\n",
    "        L (torch.Tensor): Lower triangular matrix\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    L = torch.zeros_like(A)\n",
    "    \n",
    "    # Process matrix in blocks\n",
    "    for i in range(0, n, block_size):\n",
    "        # Determine the current block size (might be smaller at the end)\n",
    "        current_block_size = min(block_size, n - i)\n",
    "        \n",
    "        # Extract blocks\n",
    "        A11 = A[i:i+current_block_size, i:i+current_block_size]\n",
    "        \n",
    "        # Compute L11 block (Cholesky of A11)\n",
    "        L11 = torch.linalg.cholesky(A11)\n",
    "        L[i:i+current_block_size, i:i+current_block_size] = L11\n",
    "        \n",
    "        # For the remaining rows in this block column\n",
    "        if i + current_block_size < n:\n",
    "            # Extract A21 block\n",
    "            A21 = A[i+current_block_size:, i:i+current_block_size]\n",
    "            \n",
    "            # Compute L21 block\n",
    "            L21 = A21 @ torch.inverse(L11.T)\n",
    "            L[i+current_block_size:, i:i+current_block_size] = L21\n",
    "            \n",
    "            # Update the remaining part of A for next iteration\n",
    "            A[i+current_block_size:, i+current_block_size:] -= L21 @ L21.T\n",
    "    \n",
    "    return L\n",
    "\n",
    "# Create a 6×6 matrix to test block Cholesky\n",
    "A = create_positive_definite_matrix(6, method=\"random\")\n",
    "\n",
    "# Standard Cholesky decomposition\n",
    "L_standard = torch.linalg.cholesky(A)\n",
    "\n",
    "# Block Cholesky decomposition\n",
    "L_block = block_cholesky(A.clone(), block_size=2)\n",
    "\n",
    "# Verification\n",
    "print(\"Error between standard and block Cholesky:\", torch.norm(L_standard - L_block).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3857e",
   "metadata": {},
   "source": [
    "We can visualize the block processing with a larger matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1696f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_block_cholesky(A, block_size=2):\n",
    "    \"\"\"Visualize the block Cholesky process.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    A_copy = A.clone()  # Work on a copy to leave original intact\n",
    "    L = torch.zeros_like(A_copy)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * ((n // block_size) + 1)))\n",
    "    \n",
    "    # Plot original matrix\n",
    "    plt.subplot(n // block_size + 2, 2, 1)\n",
    "    sns.heatmap(A_copy.numpy(), annot=True, fmt=\".1f\", cmap=\"Blues\", linewidths=.5)\n",
    "    plt.title(\"Original Matrix A\")\n",
    "    \n",
    "    step = 2\n",
    "    \n",
    "    # Process matrix in blocks\n",
    "    for i in range(0, n, block_size):\n",
    "        # Determine the current block size (might be smaller at the end)\n",
    "        current_block_size = min(block_size, n - i)\n",
    "        \n",
    "        # Extract blocks\n",
    "        A11 = A_copy[i:i+current_block_size, i:i+current_block_size]\n",
    "        \n",
    "        # Compute L11 block (Cholesky of A11)\n",
    "        L11 = torch.linalg.cholesky(A11)\n",
    "        L[i:i+current_block_size, i:i+current_block_size] = L11\n",
    "        \n",
    "        # For the remaining rows in this block column\n",
    "        if i + current_block_size < n:\n",
    "            # Extract A21 block\n",
    "            A21 = A_copy[i+current_block_size:, i:i+current_block_size]\n",
    "            \n",
    "            # Compute L21 block\n",
    "            L21 = A21 @ torch.inverse(L11.T)\n",
    "            L[i+current_block_size:, i:i+current_block_size] = L21\n",
    "            \n",
    "            # Update the remaining part of A for next iteration\n",
    "            A_copy[i+current_block_size:, i+current_block_size:] -= L21 @ L21.T\n",
    "        \n",
    "        # Plot the current state\n",
    "        plt.subplot(n // block_size + 2, 2, step)\n",
    "        \n",
    "        # Create a mask for the blocks we've processed\n",
    "        processed_mask = torch.zeros_like(A, dtype=bool)\n",
    "        processed_mask[i+current_block_size:, i:i+current_block_size] = True  # L21 block\n",
    "        processed_mask[i:i+current_block_size, i:i+current_block_size] = True  # L11 block\n",
    "        \n",
    "        sns.heatmap(L.numpy(), annot=True, fmt=\".1f\", cmap=\"Blues\", linewidths=.5, \n",
    "                   mask=~processed_mask.numpy() & (L == 0).numpy())\n",
    "        plt.title(f\"Step {i//block_size + 1}: Processed blocks L11, L21\")\n",
    "        \n",
    "        # Plot the updated matrix A\n",
    "        plt.subplot(n // block_size + 2, 2, step + 1)\n",
    "        \n",
    "        # Create a mask for the updated part of A\n",
    "        updated_mask = torch.zeros_like(A, dtype=bool)\n",
    "        if i + current_block_size < n:\n",
    "            updated_mask[i+current_block_size:, i+current_block_size:] = True  # Updated part\n",
    "        \n",
    "        sns.heatmap(A_copy.numpy(), annot=True, fmt=\".1f\", cmap=\"Oranges\", linewidths=.5, \n",
    "                   mask=~updated_mask.numpy())\n",
    "        plt.title(f\"Step {i//block_size + 1}: Updated remaining submatrix\")\n",
    "        \n",
    "        step += 2\n",
    "    \n",
    "    # Final result\n",
    "    plt.subplot(n // block_size + 2, 2, step)\n",
    "    sns.heatmap(L.numpy(), annot=True, fmt=\".1f\", cmap=\"Blues\", linewidths=.5)\n",
    "    plt.title(\"Final Cholesky Factor L\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return L\n",
    "\n",
    "# Create a 6×6 matrix to visualize block Cholesky\n",
    "A = create_positive_definite_matrix(6, method=\"random\")\n",
    "L_block_viz = visualize_block_cholesky(A, block_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bfb33",
   "metadata": {},
   "source": [
    "## 2. Modified Cholesky Decomposition\n",
    "\n",
    "Modified Cholesky decomposition is useful when dealing with matrices that are close to positive definite but may not be numerically positive definite due to roundoff errors or other numerical issues.\n",
    "\n",
    "The idea is to compute a decomposition $LL^T$ of a matrix $A + E$, where $E$ is a \"small\" perturbation matrix that ensures positive definiteness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_cholesky(A, delta=1e-6):\n",
    "    \"\"\"\n",
    "    Compute a modified Cholesky decomposition, ensuring positive definiteness.\n",
    "    \n",
    "    Parameters:\n",
    "        A (torch.Tensor): Symmetric matrix that may not be positive definite\n",
    "        delta (float): Minimum allowed value for diagonal elements\n",
    "        \n",
    "    Returns:\n",
    "        L (torch.Tensor): Lower triangular matrix\n",
    "        E (torch.Tensor): Perturbation added to make A positive definite\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    # Make a copy to avoid modifying the input\n",
    "    A_mod = A.clone()\n",
    "    E = torch.zeros_like(A)\n",
    "    \n",
    "    # Initialize L as zeros\n",
    "    L = torch.zeros_like(A)\n",
    "    \n",
    "    for j in range(n):\n",
    "        # Process diagonal element\n",
    "        if j > 0:\n",
    "            # Update diagonal element based on previously computed columns\n",
    "            for k in range(j):\n",
    "                A_mod[j, j] -= L[j, k]**2\n",
    "        \n",
    "        # If diagonal element is too small, modify it\n",
    "        if A_mod[j, j] < delta:\n",
    "            correction = delta - A_mod[j, j]\n",
    "            A_mod[j, j] = delta\n",
    "            E[j, j] = correction\n",
    "        \n",
    "        # Set diagonal element of L\n",
    "        L[j, j] = torch.sqrt(A_mod[j, j])\n",
    "        \n",
    "        # Process off-diagonal elements\n",
    "        for i in range(j+1, n):\n",
    "            if j > 0:\n",
    "                # Update based on previously computed columns\n",
    "                for k in range(j):\n",
    "                    A_mod[i, j] -= L[i, k] * L[j, k]\n",
    "            \n",
    "            # Set off-diagonal element of L\n",
    "            L[i, j] = A_mod[i, j] / L[j, j]\n",
    "    \n",
    "    return L, E\n",
    "\n",
    "# Create a matrix that is not quite positive definite\n",
    "def create_nearly_positive_definite_matrix(n, eigenvalue_min=-0.1):\n",
    "    \"\"\"Create a symmetric matrix with eigenvalues that may be slightly negative.\"\"\"\n",
    "    # Start with a random symmetric matrix\n",
    "    A = torch.randn(n, n)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    \n",
    "    # Get its eigendecomposition\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(A)\n",
    "    \n",
    "    # Modify the eigenvalues to have some small negative values\n",
    "    modified_eigenvalues = eigenvalues.clone()\n",
    "    modified_eigenvalues[-2:] = eigenvalue_min  # Set the smallest eigenvalues to a small negative value\n",
    "    \n",
    "    # Reconstruct the matrix\n",
    "    A_modified = eigenvectors @ torch.diag(modified_eigenvalues) @ eigenvectors.T\n",
    "    \n",
    "    return A_modified\n",
    "\n",
    "# Create a nearly positive definite matrix\n",
    "A_nearly_pd = create_nearly_positive_definite_matrix(5)\n",
    "\n",
    "# Check eigenvalues\n",
    "eigenvalues = torch.linalg.eigvalsh(A_nearly_pd)\n",
    "print(\"Eigenvalues of nearly positive definite matrix:\", eigenvalues)\n",
    "print(\"Is A positive definite?\", torch.all(eigenvalues > 0).item())\n",
    "\n",
    "# Standard Cholesky would fail\n",
    "try:\n",
    "    L_standard = torch.linalg.cholesky(A_nearly_pd)\n",
    "    print(\"Standard Cholesky succeeded (unexpected)\")\n",
    "except Exception as e:\n",
    "    print(\"Standard Cholesky failed with error:\", str(e))\n",
    "\n",
    "# Modified Cholesky\n",
    "L_modified, E = modified_cholesky(A_nearly_pd)\n",
    "print(\"\\nPerturbation matrix E:\")\n",
    "print(E)\n",
    "\n",
    "# Verify the modified factorization\n",
    "A_perturbed = A_nearly_pd + E\n",
    "reconstructed_A = L_modified @ L_modified.T\n",
    "print(\"\\nError in modified Cholesky reconstruction:\", torch.norm(A_perturbed - reconstructed_A).item())\n",
    "\n",
    "# Check eigenvalues of perturbed matrix\n",
    "eigenvalues_perturbed = torch.linalg.eigvalsh(A_perturbed)\n",
    "print(\"Eigenvalues of perturbed matrix:\", eigenvalues_perturbed)\n",
    "print(\"Is perturbed matrix positive definite?\", torch.all(eigenvalues_perturbed > 0).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ac858",
   "metadata": {},
   "source": [
    "Let's visualize the original matrix, the perturbation, and the modified matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efccdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_modified_cholesky(A, L, E):\n",
    "    \"\"\"Visualize the modified Cholesky decomposition.\"\"\"\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # Original matrix\n",
    "    plt.subplot(1, 4, 1)\n",
    "    sns.heatmap(A.numpy(), annot=True, fmt=\".2f\", cmap=\"Blues\", linewidths=.5)\n",
    "    plt.title(\"Original Matrix A\")\n",
    "    \n",
    "    # Perturbation matrix\n",
    "    plt.subplot(1, 4, 2)\n",
    "    sns.heatmap(E.numpy(), annot=True, fmt=\".2f\", cmap=\"Reds\", linewidths=.5)\n",
    "    plt.title(\"Perturbation Matrix E\")\n",
    "    \n",
    "    # Perturbed matrix\n",
    "    plt.subplot(1, 4, 3)\n",
    "    sns.heatmap((A + E).numpy(), annot=True, fmt=\".2f\", cmap=\"Greens\", linewidths=.5)\n",
    "    plt.title(\"Perturbed Matrix A + E\")\n",
    "    \n",
    "    # Cholesky factor of the perturbed matrix\n",
    "    plt.subplot(1, 4, 4)\n",
    "    sns.heatmap(L.numpy(), annot=True, fmt=\".2f\", cmap=\"Purples\", linewidths=.5)\n",
    "    plt.title(\"Cholesky Factor L\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the modified Cholesky decomposition\n",
    "visualize_modified_cholesky(A_nearly_pd, L_modified, E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98fccb",
   "metadata": {},
   "source": [
    "## 3. Incomplete Cholesky Factorization\n",
    "\n",
    "Incomplete Cholesky factorization is a sparse approximation of the full Cholesky decomposition. It's useful for preconditioning large sparse systems.\n",
    "\n",
    "The key idea is to only calculate entries of $L$ that correspond to non-zero entries in the sparsity pattern of the original matrix $A$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5283289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incomplete_cholesky(A, drop_tol=1e-4):\n",
    "    \"\"\"\n",
    "    Compute an incomplete Cholesky factorization with drop tolerance.\n",
    "    \n",
    "    Parameters:\n",
    "        A (torch.Tensor): Sparse positive definite matrix\n",
    "        drop_tol (float): Tolerance for dropping small entries\n",
    "        \n",
    "    Returns:\n",
    "        L (torch.Tensor): Sparse lower triangular matrix\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    # Make a copy to avoid modifying the input\n",
    "    A_copy = A.clone()\n",
    "    \n",
    "    # Initialize L as zeros\n",
    "    L = torch.zeros_like(A)\n",
    "    \n",
    "    for k in range(n):\n",
    "        # Diagonal element\n",
    "        if A_copy[k, k] <= 0:\n",
    "            # If diagonal is not positive, add a small value\n",
    "            A_copy[k, k] = 1e-8\n",
    "        \n",
    "        L[k, k] = torch.sqrt(A_copy[k, k])\n",
    "        \n",
    "        # Update the current column of L\n",
    "        for i in range(k+1, n):\n",
    "            if abs(A_copy[i, k]) > drop_tol:\n",
    "                L[i, k] = A_copy[i, k] / L[k, k]\n",
    "            else:\n",
    "                L[i, k] = 0  # Drop small entries\n",
    "        \n",
    "        # Update the trailing submatrix\n",
    "        for i in range(k+1, n):\n",
    "            for j in range(k+1, i+1):  # Only update lower triangular part\n",
    "                if L[i, k] != 0 and L[j, k] != 0:  # Only update if both entries are non-zero\n",
    "                    A_copy[i, j] -= L[i, k] * L[j, k]\n",
    "                    A_copy[j, i] = A_copy[i, j]  # Keep symmetric\n",
    "    \n",
    "    return L\n",
    "\n",
    "# Create a sparse positive definite matrix\n",
    "def create_sparse_positive_definite_matrix(n, density=0.3):\n",
    "    \"\"\"Create a sparse positive definite matrix.\"\"\"\n",
    "    # Create a random sparse matrix\n",
    "    indices = torch.randint(0, n, (2, int(n * n * density)))\n",
    "    values = torch.randn(indices.shape[1])\n",
    "    sparse = torch.sparse_coo_tensor(indices, values, (n, n)).to_dense()\n",
    "    \n",
    "    # Make it symmetric\n",
    "    sparse = sparse + sparse.T\n",
    "    \n",
    "    # Add a diagonal shift to ensure positive definiteness\n",
    "    sparse = sparse + torch.eye(n) * (n + 1)\n",
    "    \n",
    "    # Zero out some entries to make it sparse\n",
    "    mask = torch.rand(n, n) < density\n",
    "    sparse = sparse * mask\n",
    "    \n",
    "    # Ensure symmetry\n",
    "    sparse = 0.5 * (sparse + sparse.T)\n",
    "    \n",
    "    return sparse\n",
    "\n",
    "# Create a sparse positive definite matrix\n",
    "A_sparse = create_sparse_positive_definite_matrix(8, density=0.4)\n",
    "print(\"Sparsity pattern (1 = non-zero):\")\n",
    "print((A_sparse != 0).int())\n",
    "\n",
    "# Compute incomplete Cholesky factorization\n",
    "L_incomplete = incomplete_cholesky(A_sparse, drop_tol=1e-2)\n",
    "\n",
    "# Compare with full Cholesky\n",
    "L_full = torch.linalg.cholesky(A_sparse)\n",
    "\n",
    "# Compute reconstructed matrices\n",
    "A_approx = L_incomplete @ L_incomplete.T\n",
    "A_exact = L_full @ L_full.T\n",
    "\n",
    "print(\"\\nError in incomplete Cholesky reconstruction:\", torch.norm(A_sparse - A_approx).item())\n",
    "print(\"Error in full Cholesky reconstruction:\", torch.norm(A_sparse - A_exact).item())\n",
    "\n",
    "# Calculate sparsity levels\n",
    "print(f\"\\nSparsity of original matrix: {torch.sum(A_sparse != 0).item()}/{A_sparse.numel()} elements\")\n",
    "print(f\"Sparsity of incomplete Cholesky: {torch.sum(L_incomplete != 0).item()}/{L_incomplete.numel()} elements\")\n",
    "print(f\"Sparsity of full Cholesky: {torch.sum(L_full != 0).item()}/{L_full.numel()} elements\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46822a",
   "metadata": {},
   "source": [
    "Let's visualize the sparsity patterns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sparsity(A, L_incomplete, L_full):\n",
    "    \"\"\"Visualize the sparsity patterns.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original matrix\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.spy(A.numpy(), markersize=10)\n",
    "    plt.title(\"Original Matrix A\")\n",
    "    \n",
    "    # Incomplete Cholesky\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.spy(L_incomplete.numpy(), markersize=10)\n",
    "    plt.title(\"Incomplete Cholesky Factor\")\n",
    "    \n",
    "    # Full Cholesky\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.spy(L_full.numpy(), markersize=10)\n",
    "    plt.title(\"Full Cholesky Factor\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sparsity patterns\n",
    "visualize_sparsity(A_sparse, L_incomplete, L_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6980c1",
   "metadata": {},
   "source": [
    "## 4. Handling Positive Semi-Definite Matrices\n",
    "\n",
    "A positive semi-definite matrix has eigenvalues that are non-negative (≥ 0), but some may be zero.\n",
    "Standard Cholesky decomposition requires strictly positive eigenvalues. For semi-definite matrices,\n",
    "we need alternative approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positive_semidefinite_matrix(n, rank_deficiency=1):\n",
    "    \"\"\"Create a positive semidefinite matrix with specified rank deficiency.\"\"\"\n",
    "    # Create a random matrix with specific rank\n",
    "    effective_rank = n - rank_deficiency\n",
    "    X = torch.randn(n, effective_rank)\n",
    "    A = X @ X.T\n",
    "    \n",
    "    # Ensure it's symmetric (it should be already, but for numerical stability)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    \n",
    "    return A\n",
    "\n",
    "# Create a positive semidefinite matrix\n",
    "A_semidefinite = create_positive_semidefinite_matrix(5, rank_deficiency=1)\n",
    "\n",
    "# Check eigenvalues\n",
    "eigenvalues = torch.linalg.eigvalsh(A_semidefinite)\n",
    "print(\"Eigenvalues of semi-definite matrix:\", eigenvalues)\n",
    "print(\"Rank:\", torch.sum(eigenvalues > 1e-10).item())\n",
    "\n",
    "# Standard Cholesky might fail depending on how close eigenvalues are to zero\n",
    "try:\n",
    "    L_standard = torch.linalg.cholesky(A_semidefinite)\n",
    "    print(\"Standard Cholesky succeeded, but may be numerically unstable\")\n",
    "except Exception as e:\n",
    "    print(\"Standard Cholesky failed with error:\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728073f",
   "metadata": {},
   "source": [
    "### Pivoted Cholesky Decomposition\n",
    "\n",
    "Pivoted Cholesky is useful for rank-deficient matrices. It rearranges rows and columns to ensure numerical stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivoted_cholesky(A, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Compute a pivoted Cholesky decomposition.\n",
    "    \n",
    "    Parameters:\n",
    "        A (torch.Tensor): Positive semi-definite matrix\n",
    "        tol (float): Tolerance for detecting rank deficiency\n",
    "        \n",
    "    Returns:\n",
    "        L (torch.Tensor): Lower triangular matrix\n",
    "        P (torch.Tensor): Permutation matrix\n",
    "        rank (int): Numerical rank of A\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    A_copy = A.clone()\n",
    "    \n",
    "    # Initialize L as zeros\n",
    "    L = torch.zeros_like(A)\n",
    "    \n",
    "    # Initialize permutation as identity\n",
    "    perm = torch.arange(n)\n",
    "    \n",
    "    # Compute the factorization with pivoting\n",
    "    rank = 0\n",
    "    for k in range(n):\n",
    "        # Find the maximum diagonal element in the remaining submatrix\n",
    "        diag_vals = torch.diag(A_copy)[k:]\n",
    "        max_idx = torch.argmax(diag_vals) + k\n",
    "        \n",
    "        # Break if the maximum diagonal element is numerically zero\n",
    "        if A_copy[max_idx, max_idx] < tol:\n",
    "            break\n",
    "            \n",
    "        # Swap rows and columns if needed\n",
    "        if max_idx != k:\n",
    "            # Swap rows and columns in A\n",
    "            A_copy[[k, max_idx], :] = A_copy[[max_idx, k], :]\n",
    "            A_copy[:, [k, max_idx]] = A_copy[:, [max_idx, k]]\n",
    "            \n",
    "            # Swap rows in L (up to column k-1)\n",
    "            L[[k, max_idx], :k] = L[[max_idx, k], :k]\n",
    "            \n",
    "            # Update permutation\n",
    "            perm[k], perm[max_idx] = perm[max_idx], perm[k]\n",
    "        \n",
    "        # Compute diagonal element\n",
    "        L[k, k] = torch.sqrt(A_copy[k, k])\n",
    "        \n",
    "        # Compute column k of L\n",
    "        for i in range(k+1, n):\n",
    "            L[i, k] = A_copy[i, k] / L[k, k]\n",
    "        \n",
    "        # Update remaining submatrix\n",
    "        for i in range(k+1, n):\n",
    "            for j in range(k+1, n):\n",
    "                A_copy[i, j] -= L[i, k] * L[j, k]\n",
    "        \n",
    "        rank += 1\n",
    "    \n",
    "    # Create permutation matrix from permutation vector\n",
    "    P = torch.zeros(n, n)\n",
    "    for i in range(n):\n",
    "        P[i, perm[i]] = 1\n",
    "    \n",
    "    return L, P, rank\n",
    "\n",
    "# Apply pivoted Cholesky to our semidefinite matrix\n",
    "L_pivoted, P, numerical_rank = pivoted_cholesky(A_semidefinite)\n",
    "\n",
    "print(f\"Numerical rank detected: {numerical_rank}\")\n",
    "print(\"\\nPermutation matrix P:\")\n",
    "print(P)\n",
    "\n",
    "# Verify the factorization: P^T A P ≈ L L^T\n",
    "reconstructed_A = L_pivoted @ L_pivoted.T\n",
    "permuted_A = P.T @ A_semidefinite @ P\n",
    "\n",
    "print(\"\\nError in pivoted Cholesky reconstruction:\", torch.norm(permuted_A - reconstructed_A).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f87ee",
   "metadata": {},
   "source": [
    "Let's visualize the pivoted Cholesky decomposition:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e582d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pivoted_cholesky(A, L, P, rank):\n",
    "    \"\"\"Visualize the pivoted Cholesky decomposition.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original matrix\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(A.numpy(), annot=True, fmt=\".2f\", cmap=\"Blues\", linewidths=.5)\n",
    "    plt.title(\"Original Matrix A\")\n",
    "    \n",
    "    # Permuted matrix\n",
    "    plt.subplot(1, 3, 2)\n",
    "    permuted_A = P.T @ A @ P\n",
    "    sns.heatmap(permuted_A.numpy(), annot=True, fmt=\".2f\", cmap=\"Greens\", linewidths=.5)\n",
    "    plt.title(\"Permuted Matrix P^T A P\")\n",
    "    \n",
    "    # Cholesky factor\n",
    "    plt.subplot(1, 3, 3)\n",
    "    masked_L = L.clone()\n",
    "    # Mask the part below the numerical rank\n",
    "    if rank < L.shape[0]:\n",
    "        for i in range(rank, L.shape[0]):\n",
    "            masked_L[i, rank:] = 0\n",
    "            \n",
    "    sns.heatmap(masked_L.numpy(), annot=True, fmt=\".2f\", cmap=\"Purples\", linewidths=.5)\n",
    "    plt.title(f\"Cholesky Factor L (rank = {rank})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the pivoted Cholesky decomposition\n",
    "visualize_pivoted_cholesky(A_semidefinite, L_pivoted, P, numerical_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b219e1",
   "metadata": {},
   "source": [
    "## 5. Rank-1 Updates to Cholesky Factors\n",
    "\n",
    "In many applications, such as Kalman filtering or sequential least squares, we need to update a Cholesky factorization when the underlying matrix receives a small update.\n",
    "\n",
    "For a rank-1 update $A + vv^T$, we can efficiently update the Cholesky factor without recomputing it from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77def62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_update(L, v):\n",
    "    \"\"\"\n",
    "    Update a Cholesky factorization for A + v*v^T.\n",
    "    \n",
    "    Parameters:\n",
    "        L (torch.Tensor): Cholesky factor of A\n",
    "        v (torch.Tensor): Update vector\n",
    "        \n",
    "    Returns:\n",
    "        L_new (torch.Tensor): Updated Cholesky factor\n",
    "    \"\"\"\n",
    "    n = L.shape[0]\n",
    "    L_new = L.clone()\n",
    "    \n",
    "    # Copy v for the update\n",
    "    w = v.clone()\n",
    "    \n",
    "    for k in range(n):\n",
    "        # Apply rotations to maintain triangular structure\n",
    "        r = torch.sqrt(L_new[k, k]**2 + w[k]**2)\n",
    "        c = L_new[k, k] / r\n",
    "        s = w[k] / r\n",
    "        \n",
    "        # Update diagonal element\n",
    "        L_new[k, k] = r\n",
    "        \n",
    "        # Update remaining elements in this column\n",
    "        for i in range(k+1, n):\n",
    "            # Apply rotation to L_new[i, k] and w[i]\n",
    "            L_new[i, k], w[i] = c * L_new[i, k] + s * w[i], -s * L_new[i, k] + c * w[i]\n",
    "    \n",
    "    return L_new\n",
    "\n",
    "# Create a positive definite matrix and its Cholesky factor\n",
    "A = create_positive_definite_matrix(4)\n",
    "L = torch.linalg.cholesky(A)\n",
    "\n",
    "# Create a random vector for the update\n",
    "v = torch.randn(4)\n",
    "\n",
    "# Update the matrix directly\n",
    "A_updated = A + torch.outer(v, v)\n",
    "\n",
    "# Compute Cholesky of updated matrix from scratch\n",
    "L_updated_direct = torch.linalg.cholesky(A_updated)\n",
    "\n",
    "# Update the Cholesky factor incrementally\n",
    "L_updated_incremental = cholesky_update(L, v)\n",
    "\n",
    "print(\"Error between direct and incremental updates:\", \n",
    "      torch.norm(L_updated_direct - L_updated_incremental).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c7849",
   "metadata": {},
   "source": [
    "Let's visualize the update process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cholesky_update(A, L, v, L_updated):\n",
    "    \"\"\"Visualize the Cholesky update process.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original matrix\n",
    "    plt.subplot(1, 4, 1)\n",
    "    sns.heatmap(A.numpy(), annot=True, fmt=\".2f\", cmap=\"Blues\", linewidths=.5)\n",
    "    plt.title(\"Original Matrix A\")\n",
    "    \n",
    "    # Update matrix\n",
    "    plt.subplot(1, 4, 2)\n",
    "    update = torch.outer(v, v)\n",
    "    sns.heatmap(update.numpy(), annot=True, fmt=\".2f\", cmap=\"Reds\", linewidths=.5)\n",
    "    plt.title(\"Update v*v^T\")\n",
    "    \n",
    "    # Updated matrix\n",
    "    plt.subplot(1, 4, 3)\n",
    "    A_updated = A + update\n",
    "    sns.heatmap(A_updated.numpy(), annot=True, fmt=\".2f\", cmap=\"Greens\", linewidths=.5)\n",
    "    plt.title(\"Updated Matrix A + v*v^T\")\n",
    "    \n",
    "    # Updated Cholesky factor\n",
    "    plt.subplot(1, 4, 4)\n",
    "    sns.heatmap(L_updated.numpy(), annot=True, fmt=\".2f\", cmap=\"Purples\", linewidths=.5)\n",
    "    plt.title(\"Updated Cholesky Factor\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the Cholesky update\n",
    "visualize_cholesky_update(A, L, v, L_updated_incremental)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a38724",
   "metadata": {},
   "source": [
    "### Performance Comparison: Update vs. Recompute\n",
    "\n",
    "Let's compare the performance of updating the Cholesky factor versus recomputing it from scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger matrix for timing comparison\n",
    "n = 500\n",
    "A = create_positive_definite_matrix(n)\n",
    "L = torch.linalg.cholesky(A)\n",
    "\n",
    "# Create random vectors for updates\n",
    "num_updates = 10\n",
    "update_times = []\n",
    "recompute_times = []\n",
    "\n",
    "for i in range(num_updates):\n",
    "    v = torch.randn(n)\n",
    "    \n",
    "    # Time the incremental update\n",
    "    start_time = time.time()\n",
    "    L_updated_incremental = cholesky_update(L, v)\n",
    "    update_time = time.time() - start_time\n",
    "    update_times.append(update_time)\n",
    "    \n",
    "    # Update the matrix directly\n",
    "    A = A + torch.outer(v, v)\n",
    "    \n",
    "    # Time the direct recomputation\n",
    "    start_time = time.time()\n",
    "    L_updated_direct = torch.linalg.cholesky(A)\n",
    "    recompute_time = time.time() - start_time\n",
    "    recompute_times.append(recompute_time)\n",
    "    \n",
    "    # Use the incremental update for next iteration\n",
    "    L = L_updated_incremental\n",
    "    \n",
    "    print(f\"Update {i+1}:\")\n",
    "    print(f\"  Update time: {update_time:.6f} seconds\")\n",
    "    print(f\"  Recompute time: {recompute_time:.6f} seconds\")\n",
    "    print(f\"  Speedup: {recompute_time/update_time:.2f}x\")\n",
    "\n",
    "# Plot timing comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_updates+1), update_times, 'o-', label='Incremental Update')\n",
    "plt.plot(range(1, num_updates+1), recompute_times, 's-', label='Full Recomputation')\n",
    "plt.xlabel('Update Number')\n",
    "plt.ylabel('Computation Time (seconds)')\n",
    "plt.title('Cholesky Update vs. Recomputation Performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887eeef",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored various algorithms and variants of Cholesky decomposition:\n",
    "\n",
    "1. **Block Cholesky decomposition**: processes matrices in blocks for improved efficiency\n",
    "2. **Modified Cholesky decomposition**: handles matrices that are not quite positive definite\n",
    "3. **Incomplete Cholesky factorization**: creates sparse approximations for large sparse systems\n",
    "4. **Pivoted Cholesky**: deals with rank-deficient positive semi-definite matrices\n",
    "5. **Rank-1 Updates**: efficiently updates Cholesky factors without full recomputation\n",
    "\n",
    "Each of these variants is valuable in different contexts, such as numerical optimization, solving linear systems efficiently, and handling ill-conditioned or sparse matrices.\n",
    "\n",
    "In the next notebook, we'll explore practical applications of Cholesky decomposition."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
