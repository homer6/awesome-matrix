{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02344b1d",
   "metadata": {},
   "source": [
    "# ⚠️ Auto-generated Notebook\n",
    "    \n",
    "This notebook is automatically compiled from source files in `/workspaces/awesome-matrix/src/examples/11_tensor_operations_einsum`.\n",
    "**Do not edit this file directly** as your changes will be overwritten.\n",
    "\n",
    "To make changes:\n",
    "1. Edit the source file `/workspaces/awesome-matrix/src/examples/11_tensor_operations_einsum/03_applications.py` instead\n",
    "2. Run the compile script to regenerate this notebook\n",
    "\n",
    "See [COMPILE.md](docs/COMPILE.md) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc3fde",
   "metadata": {},
   "source": [
    "# Applications of Tensor Operations and Einstein Notation\n",
    "\n",
    "In this notebook, we'll explore practical applications of tensor operations and Einstein notation across various fields. Understanding how these mathematical tools are used in real-world problems helps develop intuition for working with tensors in any domain.\n",
    "\n",
    "We'll cover the following applications:\n",
    "\n",
    "1. Machine Learning - Implementing a simple neural network layer\n",
    "2. Computer Graphics - 3D transformations and projections\n",
    "3. Physics - Moment of inertia calculations\n",
    "4. Signal Processing - Image filtering and convolutions\n",
    "5. Natural Language Processing - Word embeddings and attention mechanisms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeefb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style for plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f92c3",
   "metadata": {},
   "source": [
    "## 1. Machine Learning: Neural Network Layers\n",
    "\n",
    "Tensor operations are fundamental to deep learning. Let's implement some basic neural network components using Einstein notation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1949b",
   "metadata": {},
   "source": [
    "### Dense (Fully Connected) Layer\n",
    "\n",
    "A dense layer applies a linear transformation followed by a non-linear activation:\n",
    "\n",
    "$y = \\sigma(Wx + b)$\n",
    "\n",
    "Where:\n",
    "- $W$ is the weight matrix\n",
    "- $x$ is the input vector\n",
    "- $b$ is the bias vector\n",
    "- $\\sigma$ is an activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a09542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple dense layer\n",
    "class EinsumDense:\n",
    "    def __init__(self, input_dim, output_dim, activation=None):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = torch.randn(input_dim, output_dim) * 0.1\n",
    "        self.bias = torch.zeros(output_dim)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Linear transformation using einsum\n",
    "        # Batch of inputs: shape (batch_size, input_dim)\n",
    "        # Weights: shape (input_dim, output_dim)\n",
    "        # Output: shape (batch_size, output_dim)\n",
    "        out = torch.einsum('bi,io->bo', x, self.weights) + self.bias\n",
    "        \n",
    "        # Apply activation if provided\n",
    "        if self.activation == 'relu':\n",
    "            out = torch.relu(out)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            out = torch.sigmoid(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fae08a",
   "metadata": {},
   "source": [
    "Let's test our implementation with some dummy data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch of input data\n",
    "batch_size = 4\n",
    "input_dim = 5\n",
    "output_dim = 3\n",
    "\n",
    "# Create random input data\n",
    "inputs = torch.randn(batch_size, input_dim)\n",
    "print(\"Input shape:\", inputs.shape)\n",
    "\n",
    "# Create our layer\n",
    "dense_layer = EinsumDense(input_dim, output_dim, activation='relu')\n",
    "\n",
    "# Forward pass\n",
    "outputs = dense_layer.forward(inputs)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "print(\"Output values:\\n\", outputs)\n",
    "\n",
    "# Visualize the transformation\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Input visualization\n",
    "plt.subplot(121)\n",
    "sns.heatmap(inputs.detach().numpy(), annot=True, cmap='Blues', fmt=\".2f\")\n",
    "plt.title('Input Data (batch_size × input_dim)')\n",
    "plt.xlabel('Input Dimension')\n",
    "plt.ylabel('Batch Sample')\n",
    "\n",
    "# Output visualization\n",
    "plt.subplot(122)\n",
    "sns.heatmap(outputs.detach().numpy(), annot=True, cmap='Blues', fmt=\".2f\")\n",
    "plt.title('Output Data (batch_size × output_dim)')\n",
    "plt.xlabel('Output Dimension')\n",
    "plt.ylabel('Batch Sample')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac6f1f",
   "metadata": {},
   "source": [
    "### Multi-Head Attention Layer\n",
    "\n",
    "Multi-head attention is a key component of transformer models. Let's implement a simplified version using einstein notation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a993966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EinsumMultiHeadAttention:\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_model // num_heads\n",
    "        \n",
    "        # Initialize projection matrices\n",
    "        self.W_q = torch.randn(d_model, d_model) * 0.1\n",
    "        self.W_k = torch.randn(d_model, d_model) * 0.1\n",
    "        self.W_v = torch.randn(d_model, d_model) * 0.1\n",
    "        self.W_o = torch.randn(d_model, d_model) * 0.1\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        # Project inputs to queries, keys, and values\n",
    "        # Shape: (batch, seq_len, d_model)\n",
    "        Q = torch.einsum('bsi,ij->bsj', query, self.W_q)\n",
    "        K = torch.einsum('bti,ij->btj', key, self.W_k)\n",
    "        V = torch.einsum('bti,ij->btj', value, self.W_v)\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        # Shape: (batch, num_heads, seq_len, d_head)\n",
    "        Q = Q.view(batch_size, -1, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        K = K.view(batch_size, -1, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        V = V.view(batch_size, -1, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        # Shape: (batch, num_heads, seq_len_q, seq_len_k)\n",
    "        attention_scores = torch.einsum('bhsd,bhtd->bhst', Q, K) / (self.d_head ** 0.5)\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        # Shape: (batch, num_heads, seq_len_q, d_head)\n",
    "        attention_output = torch.einsum('bhst,bhtd->bhsd', attention_weights, V)\n",
    "        \n",
    "        # Reshape back\n",
    "        # Shape: (batch, seq_len_q, d_model)\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, -1, self.d_model)\n",
    "        \n",
    "        # Final projection\n",
    "        output = torch.einsum('bsi,ij->bsj', attention_output, self.W_o)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the multi-head attention implementation\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "\n",
    "# Create random input data\n",
    "query = torch.randn(batch_size, seq_len, d_model)\n",
    "key = torch.randn(batch_size, seq_len, d_model)\n",
    "value = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Create multi-head attention layer\n",
    "mha = EinsumMultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "# Forward pass\n",
    "output, attention_weights = mha.forward(query, key, value)\n",
    "\n",
    "print(\"Input shape:\", query.shape)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)\n",
    "\n",
    "# Visualize attention weights for one head\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(attention_weights[0, 0].detach().numpy(), annot=True, cmap='Blues', fmt=\".2f\")\n",
    "plt.title('Attention Weights (Head 0)')\n",
    "plt.xlabel('Key Sequence Position')\n",
    "plt.ylabel('Query Sequence Position')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaefc69",
   "metadata": {},
   "source": [
    "## 2. Computer Graphics: 3D Transformations\n",
    "\n",
    "Tensor operations are fundamental in computer graphics for transforming objects in 3D space. Let's explore some applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e5325",
   "metadata": {},
   "source": [
    "### Homogeneous Coordinates and Transformation Matrices\n",
    "\n",
    "In 3D computer graphics, points are often represented in homogeneous coordinates to enable affine transformations using matrix multiplication. Let's implement some basic transformations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d918a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_translation_matrix(tx, ty, tz):\n",
    "    \"\"\"Create a 4x4 translation matrix for 3D homogeneous coordinates.\"\"\"\n",
    "    return torch.tensor([\n",
    "        [1, 0, 0, tx],\n",
    "        [0, 1, 0, ty],\n",
    "        [0, 0, 1, tz],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "def create_rotation_matrix_z(angle_degrees):\n",
    "    \"\"\"Create a 4x4 rotation matrix around the Z axis.\"\"\"\n",
    "    angle_rad = torch.tensor(angle_degrees * np.pi / 180)\n",
    "    cos_a = torch.cos(angle_rad)\n",
    "    sin_a = torch.sin(angle_rad)\n",
    "    \n",
    "    return torch.tensor([\n",
    "        [cos_a, -sin_a, 0, 0],\n",
    "        [sin_a, cos_a, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "def create_scaling_matrix(sx, sy, sz):\n",
    "    \"\"\"Create a 4x4 scaling matrix.\"\"\"\n",
    "    return torch.tensor([\n",
    "        [sx, 0, 0, 0],\n",
    "        [0, sy, 0, 0],\n",
    "        [0, 0, sz, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b03300",
   "metadata": {},
   "source": [
    "Let's create a simple 3D cube and apply some transformations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01937d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a cube with 8 vertices in homogeneous coordinates\n",
    "# Each vertex is [x, y, z, 1]\n",
    "cube_vertices = torch.tensor([\n",
    "    [-1, -1, -1, 1],  # 0: bottom-back-left\n",
    "    [1, -1, -1, 1],   # 1: bottom-back-right\n",
    "    [1, 1, -1, 1],    # 2: bottom-front-right\n",
    "    [-1, 1, -1, 1],   # 3: bottom-front-left\n",
    "    [-1, -1, 1, 1],   # 4: top-back-left\n",
    "    [1, -1, 1, 1],    # 5: top-back-right\n",
    "    [1, 1, 1, 1],     # 6: top-front-right\n",
    "    [-1, 1, 1, 1],    # 7: top-front-left\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Define cube edges for plotting (pairs of vertex indices)\n",
    "cube_edges = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 0),  # Bottom face\n",
    "    (4, 5), (5, 6), (6, 7), (7, 4),  # Top face\n",
    "    (0, 4), (1, 5), (2, 6), (3, 7)   # Connecting edges\n",
    "]\n",
    "\n",
    "# Create a function to visualize the cube\n",
    "def plot_cube(vertices, edges, title=\"Cube\"):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot all vertices\n",
    "    ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], \n",
    "               color='blue', s=50, label='Vertices')\n",
    "    \n",
    "    # Plot edges\n",
    "    for edge in edges:\n",
    "        ax.plot([vertices[edge[0], 0], vertices[edge[1], 0]],\n",
    "                [vertices[edge[0], 1], vertices[edge[1], 1]],\n",
    "                [vertices[edge[0], 2], vertices[edge[1], 2]],\n",
    "                color='red')\n",
    "    \n",
    "    # Set axis limits and labels\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    ax.set_box_aspect([1, 1, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the original cube\n",
    "plot_cube(cube_vertices[:, :3], cube_edges, \"Original Cube\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0160e2",
   "metadata": {},
   "source": [
    "Now let's apply a series of transformations to our cube and visualize the result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformation matrices\n",
    "translation = create_translation_matrix(2, 1, 0)\n",
    "rotation = create_rotation_matrix_z(45)\n",
    "scaling = create_scaling_matrix(1.5, 0.5, 1)\n",
    "\n",
    "# Combine transformations (order matters: first scale, then rotate, then translate)\n",
    "# Using einsum to perform the matrix multiplications\n",
    "combined_transform = torch.einsum('ij,jk->ik', \n",
    "                                 torch.einsum('ij,jk->ik', translation, rotation), \n",
    "                                 scaling)\n",
    "\n",
    "# Apply transformation to cube vertices using einsum\n",
    "# vertices_shape: (8, 4), transform_shape: (4, 4), output_shape: (8, 4)\n",
    "transformed_vertices = torch.einsum('ij,kj->ki', combined_transform, cube_vertices)\n",
    "\n",
    "# Plot the transformed cube\n",
    "plot_cube(transformed_vertices[:, :3], cube_edges, \"Transformed Cube\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a8372",
   "metadata": {},
   "source": [
    "### Perspective Projection\n",
    "\n",
    "Let's implement a perspective projection to convert our 3D cube into a 2D view:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_perspective_matrix(fov_degrees, aspect_ratio, near, far):\n",
    "    \"\"\"Create a perspective projection matrix.\"\"\"\n",
    "    fov_rad = torch.tensor(fov_degrees * np.pi / 180)\n",
    "    f = 1.0 / torch.tan(fov_rad / 2)\n",
    "    \n",
    "    return torch.tensor([\n",
    "        [f / aspect_ratio, 0, 0, 0],\n",
    "        [0, f, 0, 0],\n",
    "        [0, 0, (far + near) / (near - far), (2 * far * near) / (near - far)],\n",
    "        [0, 0, -1, 0]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "# Create a perspective projection matrix\n",
    "perspective = create_perspective_matrix(60, 1.0, 0.1, 100)\n",
    "\n",
    "# Position the cube in front of the camera\n",
    "view_transform = create_translation_matrix(0, 0, -5)\n",
    "positioned_vertices = torch.einsum('ij,kj->ki', view_transform, cube_vertices)\n",
    "\n",
    "# Apply perspective projection\n",
    "projected_vertices = torch.einsum('ij,kj->ki', perspective, positioned_vertices)\n",
    "\n",
    "# Convert from homogeneous to Euclidean coordinates (divide by w)\n",
    "w = projected_vertices[:, 3].reshape(-1, 1)\n",
    "projected_vertices_2d = projected_vertices[:, :3] / w\n",
    "\n",
    "# Plot the 2D projection\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(projected_vertices_2d[:, 0], projected_vertices_2d[:, 1], color='blue', s=50)\n",
    "\n",
    "# Draw edges in 2D\n",
    "for edge in cube_edges:\n",
    "    plt.plot([projected_vertices_2d[edge[0], 0], projected_vertices_2d[edge[1], 0]],\n",
    "             [projected_vertices_2d[edge[0], 1], projected_vertices_2d[edge[1], 1]],\n",
    "             color='red')\n",
    "\n",
    "plt.title('2D Perspective Projection of Cube')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba25ef3",
   "metadata": {},
   "source": [
    "## 3. Physics: Moment of Inertia Tensor\n",
    "\n",
    "In physics, the moment of inertia is represented as a 3×3 tensor for a three-dimensional object. Let's compute it for a simple system of point masses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdbb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a system of point masses\n",
    "# Each row represents [x, y, z, mass]\n",
    "particles = torch.tensor([\n",
    "    [1.0, 0.0, 0.0, 2.0],    # mass 2 at (1,0,0)\n",
    "    [0.0, 1.0, 0.0, 3.0],    # mass 3 at (0,1,0)\n",
    "    [0.0, 0.0, 1.0, 4.0],    # mass 4 at (0,0,1)\n",
    "    [1.0, 1.0, 1.0, 1.0]     # mass 1 at (1,1,1)\n",
    "])\n",
    "\n",
    "# Extract positions and masses\n",
    "positions = particles[:, :3]  # first 3 columns are x,y,z\n",
    "masses = particles[:, 3]      # last column is mass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b170e",
   "metadata": {},
   "source": [
    "The moment of inertia tensor I is defined as:\n",
    "\n",
    "$I_{ij} = \\sum_p m_p (r_p^2 \\delta_{ij} - r_{pi} r_{pj})$\n",
    "\n",
    "where:\n",
    "- $m_p$ is the mass of particle $p$\n",
    "- $r_p$ is the distance of particle $p$ from the origin\n",
    "- $r_{pi}$ is the $i$-th component of the position of particle $p$\n",
    "- $\\delta_{ij}$ is the Kronecker delta (1 if $i=j$, 0 otherwise)\n",
    "\n",
    "Let's implement this calculation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75253c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate r^2 for each particle\n",
    "r_squared = torch.sum(positions**2, dim=1)  # Sum of x^2 + y^2 + z^2 for each particle\n",
    "\n",
    "# Calculate the moment of inertia tensor\n",
    "I = torch.zeros((3, 3))  # Initialize 3x3 tensor\n",
    "\n",
    "# First term: sum of m_p * r_p^2 * delta_ij\n",
    "for i in range(3):\n",
    "    I[i, i] = torch.sum(masses * r_squared)\n",
    "\n",
    "# Second term: -sum of m_p * r_pi * r_pj\n",
    "# Using einsum to compute outer product of positions, then sum with weights\n",
    "weighted_positions = torch.einsum('p,pi->pi', masses, positions)  # Multiply each position by mass\n",
    "outer_products = torch.einsum('pi,pj->pij', positions, weighted_positions)  # Compute outer products\n",
    "sum_outer_products = torch.sum(outer_products, dim=0)  # Sum over all particles\n",
    "\n",
    "# Combine terms\n",
    "I = I - sum_outer_products\n",
    "\n",
    "print(\"Moment of inertia tensor:\")\n",
    "print(I)\n",
    "\n",
    "# Visualize the moment of inertia tensor\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(I.detach().numpy(), annot=True, cmap='Blues', fmt=\".2f\")\n",
    "plt.title('Moment of Inertia Tensor')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the point mass system in 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scale point sizes based on mass\n",
    "sizes = masses * 50\n",
    "\n",
    "# Plot particles\n",
    "ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], \n",
    "           s=sizes, c=masses, cmap='viridis', label='Point Masses')\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('System of Point Masses')\n",
    "\n",
    "# Add a colorbar for mass\n",
    "cbar = plt.colorbar(ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], \n",
    "                              s=sizes, c=masses, cmap='viridis'), ax=ax)\n",
    "cbar.set_label('Mass')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0452c5",
   "metadata": {},
   "source": [
    "## 4. Signal Processing: Image Filtering\n",
    "\n",
    "Convolution operations, which are essential for image filtering, can be expressed efficiently using einsum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 8x8 grayscale image\n",
    "image = torch.zeros((8, 8))\n",
    "image[2:6, 2:6] = 1.0  # Create a white square in the middle\n",
    "image[4, 4] = 0.0      # Add a black pixel in the center of the square\n",
    "\n",
    "# Define some common image filters\n",
    "sobel_x = torch.tensor([\n",
    "    [-1, 0, 1],\n",
    "    [-2, 0, 2],\n",
    "    [-1, 0, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "sobel_y = torch.tensor([\n",
    "    [-1, -2, -1],\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "gaussian = torch.tensor([\n",
    "    [1, 2, 1],\n",
    "    [2, 4, 2],\n",
    "    [1, 2, 1]\n",
    "], dtype=torch.float32) / 16  # Normalize to sum to 1\n",
    "\n",
    "# Define a function to apply filters using einsum\n",
    "def apply_filter(image, kernel):\n",
    "    height, width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "    \n",
    "    # Initialize output\n",
    "    output = torch.zeros((height - k_height + 1, width - k_width + 1))\n",
    "    \n",
    "    # Extract patches\n",
    "    patches = torch.zeros((height - k_height + 1, width - k_width + 1, k_height, k_width))\n",
    "    for i in range(height - k_height + 1):\n",
    "        for j in range(width - k_width + 1):\n",
    "            patches[i, j] = image[i:i+k_height, j:j+k_width]\n",
    "    \n",
    "    # Apply convolution using einsum\n",
    "    output = torch.einsum('ijkl,kl->ij', patches, kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Apply filters to our image\n",
    "filtered_sobel_x = apply_filter(image, sobel_x)\n",
    "filtered_sobel_y = apply_filter(image, sobel_y)\n",
    "filtered_gaussian = apply_filter(image, gaussian)\n",
    "\n",
    "# Compute magnitude of Sobel gradients (edge detection)\n",
    "edge_magnitude = torch.sqrt(filtered_sobel_x**2 + filtered_sobel_y**2)\n",
    "\n",
    "# Visualize the results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original image\n",
    "im0 = axes[0, 0].imshow(image, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image')\n",
    "plt.colorbar(im0, ax=axes[0, 0])\n",
    "\n",
    "# Sobel-x\n",
    "im1 = axes[0, 1].imshow(filtered_sobel_x, cmap='coolwarm')\n",
    "axes[0, 1].set_title('Sobel-X Filter (Horizontal Edges)')\n",
    "plt.colorbar(im1, ax=axes[0, 1])\n",
    "\n",
    "# Sobel-y\n",
    "im2 = axes[0, 2].imshow(filtered_sobel_y, cmap='coolwarm')\n",
    "axes[0, 2].set_title('Sobel-Y Filter (Vertical Edges)')\n",
    "plt.colorbar(im2, ax=axes[0, 2])\n",
    "\n",
    "# Edge magnitude\n",
    "im3 = axes[1, 0].imshow(edge_magnitude, cmap='viridis')\n",
    "axes[1, 0].set_title('Edge Magnitude')\n",
    "plt.colorbar(im3, ax=axes[1, 0])\n",
    "\n",
    "# Gaussian blur\n",
    "im4 = axes[1, 1].imshow(filtered_gaussian, cmap='gray')\n",
    "axes[1, 1].set_title('Gaussian Blur')\n",
    "plt.colorbar(im4, ax=axes[1, 1])\n",
    "\n",
    "# Show the Sobel-X kernel\n",
    "im5 = axes[1, 2].imshow(sobel_x, cmap='coolwarm')\n",
    "axes[1, 2].set_title('Sobel-X Kernel')\n",
    "plt.colorbar(im5, ax=axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a74c4",
   "metadata": {},
   "source": [
    "## 5. Natural Language Processing: Word Embeddings\n",
    "\n",
    "Word embeddings represent words as dense vectors in a continuous vector space. Let's simulate a simple word embedding system and compute word similarities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e15a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small vocabulary with 10 words and 5-dimensional embeddings\n",
    "vocabulary = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\", \"cat\", \"mouse\"]\n",
    "vocab_size = len(vocabulary)\n",
    "embedding_dim = 5\n",
    "\n",
    "# Generate random word embeddings (in practice, these would be learned)\n",
    "word_embeddings = torch.randn(vocab_size, embedding_dim)\n",
    "\n",
    "# Create a dictionary mapping words to their embeddings\n",
    "word_to_idx = {word: i for i, word in enumerate(vocabulary)}\n",
    "word_to_embedding = {word: word_embeddings[i] for word, i in word_to_idx.items()}\n",
    "\n",
    "# Compute cosine similarity between all pairs of words\n",
    "# First normalize all embeddings\n",
    "normalized_embeddings = word_embeddings / torch.norm(word_embeddings, dim=1, keepdim=True)\n",
    "\n",
    "# Compute all pairwise dot products using einsum\n",
    "# This gives us the cosine similarity since vectors are normalized\n",
    "similarity_matrix = torch.einsum('ie,je->ij', normalized_embeddings, normalized_embeddings)\n",
    "\n",
    "# Visualize the similarity matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_matrix.detach().numpy(), annot=True, cmap='Blues', fmt=\".2f\",\n",
    "            xticklabels=vocabulary, yticklabels=vocabulary)\n",
    "plt.title('Word Embedding Cosine Similarities')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567f478",
   "metadata": {},
   "source": [
    "### Word Context Prediction\n",
    "\n",
    "Let's simulate a simple word2vec-like model that predicts context words given a center word:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple sentence for context\n",
    "sentence = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
    "\n",
    "# Create context pairs (center word, context word)\n",
    "window_size = 2\n",
    "context_pairs = []\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    center_word = sentence[i]\n",
    "    for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
    "        if i != j:  # Skip the center word itself\n",
    "            context_word = sentence[j]\n",
    "            context_pairs.append((center_word, context_word))\n",
    "\n",
    "# Convert words to indices\n",
    "context_indices = [(word_to_idx[center], word_to_idx[context]) \n",
    "                  for center, context in context_pairs \n",
    "                  if center in word_to_idx and context in word_to_idx]\n",
    "\n",
    "# Prepare data for batch processing\n",
    "center_indices = torch.tensor([center for center, _ in context_indices])\n",
    "context_indices = torch.tensor([context for _, context in context_indices])\n",
    "\n",
    "# Lookup embeddings\n",
    "center_embeddings = word_embeddings[center_indices]\n",
    "context_embeddings = word_embeddings[context_indices]\n",
    "\n",
    "# Compute dot products between center and context words\n",
    "# This simulates the prediction scores in skip-gram model\n",
    "dot_products = torch.einsum('be,be->b', center_embeddings, context_embeddings)\n",
    "\n",
    "# Convert to probabilities using sigmoid\n",
    "probabilities = torch.sigmoid(dot_products)\n",
    "\n",
    "# Show results\n",
    "result_data = {\n",
    "    'Center Word': [vocabulary[idx.item()] for idx in center_indices],\n",
    "    'Context Word': [vocabulary[idx.item()] for idx in context_indices],\n",
    "    'Probability': probabilities.detach().numpy()\n",
    "}\n",
    "\n",
    "print(\"Word context prediction probabilities:\")\n",
    "for i in range(len(result_data['Center Word'])):\n",
    "    print(f\"{result_data['Center Word'][i]} → {result_data['Context Word'][i]}: {result_data['Probability'][i]:.3f}\")\n",
    "\n",
    "# Plot probabilities for a specific center word\n",
    "center_word = \"fox\"\n",
    "if center_word in word_to_idx:\n",
    "    center_idx = word_to_idx[center_word]\n",
    "    mask = center_indices == center_idx\n",
    "    \n",
    "    if torch.any(mask):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        context_words = [vocabulary[idx.item()] for idx in context_indices[mask]]\n",
    "        probs = probabilities[mask].detach().numpy()\n",
    "        \n",
    "        plt.bar(context_words, probs, color='skyblue')\n",
    "        plt.title(f'Context Word Probabilities for \"{center_word}\"')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113e64b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored practical applications of tensor operations and Einstein notation across different domains:\n",
    "\n",
    "1. **Machine Learning**: We implemented neural network layers including multi-head attention.\n",
    "\n",
    "2. **Computer Graphics**: We performed 3D transformations and perspective projection.\n",
    "\n",
    "3. **Physics**: We calculated the moment of inertia tensor for a system of point masses.\n",
    "\n",
    "4. **Signal Processing**: We implemented image filtering operations using convolution.\n",
    "\n",
    "5. **Natural Language Processing**: We worked with word embeddings and context prediction.\n",
    "\n",
    "These examples demonstrate how tensor operations and Einstein notation provide a powerful and concise framework for expressing complex computations across diverse fields. By understanding these fundamental operations, you can develop intuition for working with higher-dimensional data in any domain.\n",
    "\n",
    "The ability to clearly express operations on tensors is essential for modern computational science, and Einstein notation provides a compact, readable syntax for these operations. As data becomes increasingly high-dimensional, these tools become even more valuable."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
