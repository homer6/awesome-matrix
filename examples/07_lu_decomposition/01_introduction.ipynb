{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1507753f",
   "metadata": {},
   "source": [
    "# ⚠️ Auto-generated Notebook\n",
    "    \n",
    "This notebook is automatically compiled from source files in `/workspaces/awesome-matrix/src/examples/07_lu_decomposition`.\n",
    "**Do not edit this file directly** as your changes will be overwritten.\n",
    "\n",
    "To make changes:\n",
    "1. Edit the source file `/workspaces/awesome-matrix/src/examples/07_lu_decomposition/01_introduction.py` instead\n",
    "2. Run the compile script to regenerate this notebook\n",
    "\n",
    "See [COMPILE.md](docs/COMPILE.md) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258707cd",
   "metadata": {},
   "source": [
    "# LU Decomposition: Introduction\n",
    "\n",
    "LU decomposition (or LU factorization) is a fundamental matrix decomposition technique that expresses a matrix as the product of a lower triangular matrix (L) and an upper triangular matrix (U). It serves as the computational foundation for various numerical algorithms, particularly for solving systems of linear equations.\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Understand the concept of LU decomposition\n",
    "2. Implement LU decomposition from scratch\n",
    "3. Visualize the decomposition process\n",
    "4. Compare with built-in functions\n",
    "\n",
    "LU decomposition is closely related to Gaussian elimination, which is the process of transforming a matrix into row echelon form (upper triangular). The L matrix captures the multipliers used during this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import time\n",
    "import scipy.linalg\n",
    "\n",
    "# For better looking plots\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define a custom colormap (light blue to dark blue)\n",
    "colors = [(0.95, 0.95, 1), (0.0, 0.2, 0.6)]\n",
    "blue_cmap = LinearSegmentedColormap.from_list('CustomBlue', colors, N=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a678bf2",
   "metadata": {},
   "source": [
    "## Basic Concept of LU Decomposition\n",
    "\n",
    "For a square matrix $A$, the LU decomposition finds matrices $L$ and $U$ such that:\n",
    "\n",
    "$A = LU$\n",
    "\n",
    "where:\n",
    "- $L$ is a lower triangular matrix (all elements above the main diagonal are zero)\n",
    "- $U$ is an upper triangular matrix (all elements below the main diagonal are zero)\n",
    "\n",
    "In many cases, we also set the diagonal elements of $L$ to 1, which makes the decomposition unique.\n",
    "\n",
    "Let's first create a simple example to demonstrate the concept:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5eec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example_matrix(n=3, method=\"random\"):\n",
    "    \"\"\"Create a matrix for LU decomposition demonstration.\"\"\"\n",
    "    if method == \"random\":\n",
    "        # Create a random matrix\n",
    "        A = torch.rand(n, n) * 10\n",
    "        # Make it diagonally dominant for numerical stability\n",
    "        for i in range(n):\n",
    "            A[i, i] = torch.sum(torch.abs(A[i, :])) + 1.0\n",
    "    elif method == \"simple\":\n",
    "        # Create a simple matrix with known decomposition\n",
    "        A = torch.tensor([\n",
    "            [2.0, 1.0, 1.0],\n",
    "            [4.0, 3.0, 3.0],\n",
    "            [8.0, 7.0, 9.0]\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "    \n",
    "    return A\n",
    "\n",
    "# Create a simple example matrix\n",
    "A_simple = create_example_matrix(method=\"simple\")\n",
    "\n",
    "# Display the matrix\n",
    "def plot_matrix(matrix, title=\"Matrix\", annotate=True, cmap=blue_cmap):\n",
    "    \"\"\"Plot a matrix as a heatmap with annotations.\"\"\"\n",
    "    if isinstance(matrix, torch.Tensor):\n",
    "        matrix_np = matrix.numpy()\n",
    "    else:\n",
    "        matrix_np = matrix\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(matrix_np, annot=annotate, fmt=\".2f\", cmap=cmap, \n",
    "                    linewidths=1, cbar=True)\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Add row and column indices\n",
    "    ax.set_xticks(np.arange(matrix_np.shape[1]) + 0.5)\n",
    "    ax.set_yticks(np.arange(matrix_np.shape[0]) + 0.5)\n",
    "    ax.set_xticklabels([f\"Col {i+1}\" for i in range(matrix_np.shape[1])])\n",
    "    ax.set_yticklabels([f\"Row {i+1}\" for i in range(matrix_np.shape[0])])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_matrix(A_simple, \"Example Matrix A\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcec4ab",
   "metadata": {},
   "source": [
    "## LU Decomposition Algorithm\n",
    "\n",
    "The LU decomposition can be computed using the Gaussian elimination process. The key idea is to:\n",
    "\n",
    "1. Iteratively transform the matrix $A$ into an upper triangular matrix $U$ using elementary row operations\n",
    "2. Keep track of the multipliers used in each step to form the lower triangular matrix $L$\n",
    "\n",
    "Let's implement the algorithm from scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lu_decomposition(A, pivot=False):\n",
    "    \"\"\"\n",
    "    Perform LU decomposition on matrix A.\n",
    "    \n",
    "    Args:\n",
    "        A: Input matrix as a PyTorch tensor\n",
    "        pivot: Whether to use partial pivoting (PA = LU)\n",
    "    \n",
    "    Returns:\n",
    "        L: Lower triangular matrix\n",
    "        U: Upper triangular matrix\n",
    "        P: Permutation matrix (if pivot=True)\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Make a copy to avoid modifying the original matrix\n",
    "    A_work = A.clone()\n",
    "    \n",
    "    # Initialize L as identity matrix\n",
    "    L = torch.eye(n, dtype=A.dtype)\n",
    "    \n",
    "    # Initialize permutation matrix (for pivoting)\n",
    "    P = torch.eye(n, dtype=A.dtype)\n",
    "    \n",
    "    # Perform Gaussian elimination\n",
    "    for k in range(n-1):  # Loop through each column\n",
    "        # Partial pivoting (optional)\n",
    "        if pivot:\n",
    "            # Find the index of the maximum absolute value in the current column (from k to n)\n",
    "            max_idx = torch.argmax(torch.abs(A_work[k:, k])) + k\n",
    "            \n",
    "            # If the max is not at the current row, swap rows\n",
    "            if max_idx != k:\n",
    "                # Swap rows in A_work\n",
    "                A_work[[k, max_idx], :] = A_work[[max_idx, k], :]\n",
    "                \n",
    "                # Swap rows in P (up to the current column)\n",
    "                P[[k, max_idx], :] = P[[max_idx, k], :]\n",
    "                \n",
    "                # Swap rows in L (up to the current column)\n",
    "                if k > 0:\n",
    "                    L[[k, max_idx], :k] = L[[max_idx, k], :k]\n",
    "        \n",
    "        # Skip if the current pivot is zero (singular matrix)\n",
    "        if torch.abs(A_work[k, k]) < 1e-10:\n",
    "            continue\n",
    "        \n",
    "        # For each row below the current row\n",
    "        for i in range(k+1, n):\n",
    "            # Compute the multiplier\n",
    "            factor = A_work[i, k] / A_work[k, k]\n",
    "            L[i, k] = factor\n",
    "            \n",
    "            # Update the current row by subtracting the scaled pivot row\n",
    "            A_work[i, k:] -= factor * A_work[k, k:]\n",
    "    \n",
    "    # The resulting A_work is now the upper triangular matrix U\n",
    "    U = A_work\n",
    "    \n",
    "    if pivot:\n",
    "        return P, L, U\n",
    "    else:\n",
    "        return L, U\n",
    "\n",
    "# Test the LU decomposition on our example matrix\n",
    "L_simple, U_simple = lu_decomposition(A_simple)\n",
    "\n",
    "# Display the results\n",
    "plot_matrix(L_simple, \"Lower Triangular Matrix (L)\")\n",
    "plot_matrix(U_simple, \"Upper Triangular Matrix (U)\")\n",
    "\n",
    "# Check that A = LU\n",
    "A_reconstructed = L_simple @ U_simple\n",
    "plot_matrix(A_reconstructed, \"Reconstructed Matrix (L×U)\")\n",
    "\n",
    "# Calculate reconstruction error\n",
    "reconstruction_error = torch.norm(A_simple - A_reconstructed).item()\n",
    "print(f\"Reconstruction error: {reconstruction_error:.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0f3d4",
   "metadata": {},
   "source": [
    "### Visualizing the Decomposition\n",
    "\n",
    "Let's visualize the LU decomposition process more intuitively by showing the step-by-step Gaussian elimination:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a48c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lu_decomposition(A):\n",
    "    \"\"\"Visualize the step-by-step process of LU decomposition.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Make a copy to avoid modifying the original matrix\n",
    "    A_work = A.clone()\n",
    "    \n",
    "    # Initialize L as identity matrix\n",
    "    L = torch.eye(n, dtype=A.dtype)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * n))\n",
    "    \n",
    "    # Plot the original matrix\n",
    "    plt.subplot(n + 1, 3, 1)\n",
    "    sns.heatmap(A.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Original Matrix A\")\n",
    "    \n",
    "    # Plot initial L and U\n",
    "    plt.subplot(n + 1, 3, 2)\n",
    "    sns.heatmap(L.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Initial L (Identity)\")\n",
    "    \n",
    "    plt.subplot(n + 1, 3, 3)\n",
    "    sns.heatmap(A_work.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Initial U (Copy of A)\")\n",
    "    \n",
    "    # Perform Gaussian elimination step by step\n",
    "    for k in range(n-1):  # Loop through each column\n",
    "        # For each row below the current row\n",
    "        for i in range(k+1, n):\n",
    "            # Compute the multiplier\n",
    "            factor = A_work[i, k] / A_work[k, k]\n",
    "            L[i, k] = factor\n",
    "            \n",
    "            # Update the current row by subtracting the scaled pivot row\n",
    "            A_work[i, k:] -= factor * A_work[k, k:]\n",
    "        \n",
    "        # Plot the current state\n",
    "        plt.subplot(n + 1, 3, (k + 2) * 3 - 2)\n",
    "        sns.heatmap(A.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "        plt.title(f\"Original Matrix A (Step {k+1})\")\n",
    "        \n",
    "        plt.subplot(n + 1, 3, (k + 2) * 3 - 1)\n",
    "        sns.heatmap(L.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "        plt.title(f\"L Matrix (Step {k+1})\")\n",
    "        \n",
    "        plt.subplot(n + 1, 3, (k + 2) * 3)\n",
    "        sns.heatmap(A_work.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "        plt.title(f\"U Matrix (Step {k+1})\")\n",
    "    \n",
    "    # The final result\n",
    "    plt.subplot(n + 1, 3, n * 3 + 1)\n",
    "    reconstructed = L @ A_work\n",
    "    sns.heatmap(reconstructed.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Reconstructed A = LU\")\n",
    "    \n",
    "    plt.subplot(n + 1, 3, n * 3 + 2)\n",
    "    sns.heatmap(L.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Final L\")\n",
    "    \n",
    "    plt.subplot(n + 1, 3, n * 3 + 3)\n",
    "    sns.heatmap(A_work.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Final U\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return L, A_work\n",
    "\n",
    "# Visualize the LU decomposition process on our example matrix\n",
    "L_visual, U_visual = visualize_lu_decomposition(A_simple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d0935",
   "metadata": {},
   "source": [
    "## Using Built-in LU Decomposition Functions\n",
    "\n",
    "Both NumPy and PyTorch provide built-in functions for LU decomposition. Let's use them and compare the results with our implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lu_implementations(A):\n",
    "    \"\"\"Compare different LU decomposition implementations.\"\"\"\n",
    "    # Our implementation\n",
    "    start_time = time.time()\n",
    "    L_ours, U_ours = lu_decomposition(A)\n",
    "    our_time = time.time() - start_time\n",
    "    \n",
    "    # NumPy implementation (using SciPy)\n",
    "    A_np = A.numpy()\n",
    "    start_time = time.time()\n",
    "    P_np, L_np, U_np = scipy.linalg.lu(A_np)\n",
    "    np_time = time.time() - start_time\n",
    "    \n",
    "    # PyTorch implementation\n",
    "    start_time = time.time()\n",
    "    LU, pivots = torch.linalg.lu_factor(A)\n",
    "    # PyTorch's output is a bit different; we need to extract L and U\n",
    "    n = A.shape[0]\n",
    "    U_torch = torch.triu(LU)\n",
    "    L_torch = torch.tril(LU, -1) + torch.eye(n)\n",
    "    torch_time = time.time() - start_time\n",
    "    \n",
    "    # Convert to PyTorch tensors for consistency\n",
    "    L_np_tensor = torch.from_numpy(L_np)\n",
    "    U_np_tensor = torch.from_numpy(U_np)\n",
    "    \n",
    "    # Calculate reconstruction errors\n",
    "    our_error = torch.norm(A - L_ours @ U_ours).item()\n",
    "    np_error = torch.norm(A - torch.from_numpy(P_np.T) @ L_np_tensor @ U_np_tensor).item()\n",
    "    torch_error = torch.norm(A - L_torch @ U_torch).item()\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Our implementation\n",
    "    plt.subplot(3, 3, 1)\n",
    "    sns.heatmap(L_ours.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Our L\")\n",
    "    \n",
    "    plt.subplot(3, 3, 2)\n",
    "    sns.heatmap(U_ours.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Our U\")\n",
    "    \n",
    "    plt.subplot(3, 3, 3)\n",
    "    reconstructed = L_ours @ U_ours\n",
    "    sns.heatmap(reconstructed.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(f\"Our LU\\nError: {our_error:.2e}, Time: {our_time:.4f}s\")\n",
    "    \n",
    "    # NumPy implementation\n",
    "    plt.subplot(3, 3, 4)\n",
    "    sns.heatmap(L_np, annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"NumPy L\")\n",
    "    \n",
    "    plt.subplot(3, 3, 5)\n",
    "    sns.heatmap(U_np, annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"NumPy U\")\n",
    "    \n",
    "    plt.subplot(3, 3, 6)\n",
    "    reconstructed_np = P_np.T @ L_np @ U_np\n",
    "    sns.heatmap(reconstructed_np, annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(f\"NumPy PLU\\nError: {np_error:.2e}, Time: {np_time:.4f}s\")\n",
    "    \n",
    "    # PyTorch implementation\n",
    "    plt.subplot(3, 3, 7)\n",
    "    sns.heatmap(L_torch.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"PyTorch L\")\n",
    "    \n",
    "    plt.subplot(3, 3, 8)\n",
    "    sns.heatmap(U_torch.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"PyTorch U\")\n",
    "    \n",
    "    plt.subplot(3, 3, 9)\n",
    "    reconstructed_torch = L_torch @ U_torch\n",
    "    sns.heatmap(reconstructed_torch.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(f\"PyTorch LU\\nError: {torch_error:.2e}, Time: {torch_time:.4f}s\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the performance comparison\n",
    "    print(\"Performance Comparison:\")\n",
    "    print(f\"Our Implementation:  Error = {our_error:.2e}, Time = {our_time:.4f}s\")\n",
    "    print(f\"NumPy Implementation: Error = {np_error:.2e}, Time = {np_time:.4f}s\")\n",
    "    print(f\"PyTorch Implementation: Error = {torch_error:.2e}, Time = {torch_time:.4f}s\")\n",
    "\n",
    "# Compare different LU implementations on our example matrix\n",
    "compare_lu_implementations(A_simple)\n",
    "\n",
    "# Create and test a larger random matrix\n",
    "A_random = create_example_matrix(n=5, method=\"random\")\n",
    "compare_lu_implementations(A_random)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd687a",
   "metadata": {},
   "source": [
    "## The Need for Pivoting\n",
    "\n",
    "In the basic LU decomposition, we assume that we can use the diagonal element as a pivot for each step of Gaussian elimination. However, if the pivot element is zero or very small, this can lead to numerical instability.\n",
    "\n",
    "**Partial pivoting** addresses this issue by selecting the largest absolute value in the current column as the pivot. This results in a permutation of the rows, so we get $PA = LU$ where $P$ is a permutation matrix.\n",
    "\n",
    "Let's create a matrix that requires pivoting and demonstrate the difference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94381a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivoting_example():\n",
    "    \"\"\"Create an example matrix that requires pivoting.\"\"\"\n",
    "    # Create a matrix where the first pivot would be small or zero\n",
    "    A = torch.tensor([\n",
    "        [0.001, 1.0, 2.0],\n",
    "        [3.0, 4.0, 5.0],\n",
    "        [6.0, 7.0, 8.0]\n",
    "    ])\n",
    "    \n",
    "    return A\n",
    "\n",
    "A_pivot = create_pivoting_example()\n",
    "plot_matrix(A_pivot, \"Matrix Requiring Pivoting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4886d968",
   "metadata": {},
   "source": [
    "### LU Decomposition Without Pivoting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee13b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pivoting_comparison(A):\n",
    "    \"\"\"Visualize LU decomposition with and without pivoting.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # LU without pivoting\n",
    "    try:\n",
    "        L_no_pivot, U_no_pivot = lu_decomposition(A, pivot=False)\n",
    "        no_pivot_error = torch.norm(A - L_no_pivot @ U_no_pivot).item()\n",
    "        no_pivot_failed = False\n",
    "    except Exception as e:\n",
    "        print(f\"LU without pivoting failed: {e}\")\n",
    "        no_pivot_failed = True\n",
    "    \n",
    "    # LU with pivoting\n",
    "    P_pivot, L_pivot, U_pivot = lu_decomposition(A, pivot=True)\n",
    "    pivot_error = torch.norm(P_pivot @ A - L_pivot @ U_pivot).item()\n",
    "    \n",
    "    # Plot the results\n",
    "    if no_pivot_failed:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        cols = 3\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        cols = 3\n",
    "        rows = 2\n",
    "    \n",
    "    # Original matrix\n",
    "    plt.subplot(rows if not no_pivot_failed else 1, cols, 1)\n",
    "    sns.heatmap(A.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"Original Matrix A\")\n",
    "    \n",
    "    if not no_pivot_failed:\n",
    "        # Without pivoting\n",
    "        plt.subplot(rows, cols, 2)\n",
    "        sns.heatmap(L_no_pivot.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "        plt.title(\"L (No Pivoting)\")\n",
    "        \n",
    "        plt.subplot(rows, cols, 3)\n",
    "        sns.heatmap(U_no_pivot.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "        plt.title(\"U (No Pivoting)\")\n",
    "        \n",
    "        plt.subplot(rows, cols, 4)\n",
    "        reconstructed_no_pivot = L_no_pivot @ U_no_pivot\n",
    "        sns.heatmap(reconstructed_no_pivot.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "        plt.title(f\"LU (No Pivoting)\\nError: {no_pivot_error:.2e}\")\n",
    "    \n",
    "    # With pivoting\n",
    "    base_idx = 4 if not no_pivot_failed else 2\n",
    "    plt.subplot(rows if not no_pivot_failed else 1, cols, base_idx)\n",
    "    sns.heatmap(P_pivot.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"P (With Pivoting)\")\n",
    "    \n",
    "    plt.subplot(rows if not no_pivot_failed else 1, cols, base_idx + 1)\n",
    "    sns.heatmap(L_pivot.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"L (With Pivoting)\")\n",
    "    \n",
    "    plt.subplot(rows if not no_pivot_failed else 1, cols, base_idx + 2)\n",
    "    sns.heatmap(U_pivot.numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "    plt.title(\"U (With Pivoting)\")\n",
    "    \n",
    "    if not no_pivot_failed:\n",
    "        plt.subplot(rows, cols, base_idx + 3)\n",
    "        reconstructed_pivot = L_pivot @ U_pivot\n",
    "        sns.heatmap((P_pivot @ A).numpy(), annot=True, fmt=\".2f\", cmap=blue_cmap, linewidths=1)\n",
    "        plt.title(f\"PA (With Pivoting)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the performance comparison\n",
    "    print(\"Performance Comparison:\")\n",
    "    if not no_pivot_failed:\n",
    "        print(f\"Without Pivoting: Error = {no_pivot_error:.2e}\")\n",
    "    print(f\"With Pivoting: Error = {pivot_error:.2e}\")\n",
    "\n",
    "# Visualize the effect of pivoting\n",
    "visualize_pivoting_comparison(A_pivot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c055abdb",
   "metadata": {},
   "source": [
    "## Real-World Example: 3D Grid Problem\n",
    "\n",
    "Let's consider a practical application: solving a 3D Poisson equation on a grid. This kind of problem appears in physics simulations, fluid dynamics, and many other fields.\n",
    "\n",
    "The system of equations that arises from discretizing a 3D Poisson equation often has a specific structure, and LU decomposition can be an efficient way to solve it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362eadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_grid_matrix(nx=4, ny=4, nz=4):\n",
    "    \"\"\"Create a matrix representing a 3D grid problem.\"\"\"\n",
    "    n = nx * ny * nz  # Total number of grid points\n",
    "    A = torch.zeros((n, n))\n",
    "    \n",
    "    # Fill the matrix based on a 7-point stencil (central difference)\n",
    "    for k in range(nz):\n",
    "        for j in range(ny):\n",
    "            for i in range(nx):\n",
    "                idx = i + j * nx + k * nx * ny  # Flattened 3D index\n",
    "                \n",
    "                # Diagonal element (center point)\n",
    "                A[idx, idx] = 6.0\n",
    "                \n",
    "                # Neighbors in x-direction\n",
    "                if i > 0:\n",
    "                    A[idx, idx-1] = -1.0\n",
    "                if i < nx-1:\n",
    "                    A[idx, idx+1] = -1.0\n",
    "                \n",
    "                # Neighbors in y-direction\n",
    "                if j > 0:\n",
    "                    A[idx, idx-nx] = -1.0\n",
    "                if j < ny-1:\n",
    "                    A[idx, idx+nx] = -1.0\n",
    "                \n",
    "                # Neighbors in z-direction\n",
    "                if k > 0:\n",
    "                    A[idx, idx-nx*ny] = -1.0\n",
    "                if k < nz-1:\n",
    "                    A[idx, idx+nx*ny] = -1.0\n",
    "    \n",
    "    return A\n",
    "\n",
    "# Create a small 3D grid matrix for visualization\n",
    "A_3d_small = create_3d_grid_matrix(nx=2, ny=2, nz=2)\n",
    "plot_matrix(A_3d_small, \"3D Grid Matrix (2×2×2)\")\n",
    "\n",
    "# Create a larger matrix for performance testing\n",
    "A_3d = create_3d_grid_matrix(nx=4, ny=4, nz=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708c8e2",
   "metadata": {},
   "source": [
    "### Visualizing the Sparsity Pattern\n",
    "\n",
    "The matrix from a 3D grid problem has a specific sparsity pattern. Let's visualize it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sparsity(A, title=\"Sparsity Pattern\"):\n",
    "    \"\"\"Plot the sparsity pattern of a matrix.\"\"\"\n",
    "    if isinstance(A, torch.Tensor):\n",
    "        A_np = A.numpy()\n",
    "    else:\n",
    "        A_np = A\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.spy(A_np, marker='.', markersize=2)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate sparsity\n",
    "    n_elements = A_np.size\n",
    "    n_nonzero = np.count_nonzero(A_np)\n",
    "    sparsity = 1.0 - (n_nonzero / n_elements)\n",
    "    \n",
    "    print(f\"Matrix size: {A_np.shape}\")\n",
    "    print(f\"Number of non-zero elements: {n_nonzero}\")\n",
    "    print(f\"Sparsity: {sparsity:.2%}\")\n",
    "\n",
    "# Visualize the sparsity pattern\n",
    "plot_sparsity(A_3d, \"3D Grid Matrix Sparsity Pattern\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecc992",
   "metadata": {},
   "source": [
    "### Solving a Linear System with LU Decomposition\n",
    "\n",
    "Now let's solve a linear system $Ax = b$ using LU decomposition:\n",
    "\n",
    "1. Decompose $A = LU$\n",
    "2. Solve $Ly = b$ for $y$ (forward substitution)\n",
    "3. Solve $Ux = y$ for $x$ (backward substitution)\n",
    "\n",
    "This is more efficient than directly inverting the matrix, especially for large matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4038873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_lu(A, b, use_pivoting=True):\n",
    "    \"\"\"Solve a linear system Ax = b using LU decomposition.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Perform LU decomposition\n",
    "    if use_pivoting:\n",
    "        P, L, U = lu_decomposition(A, pivot=True)\n",
    "        b_permuted = P @ b\n",
    "    else:\n",
    "        L, U = lu_decomposition(A, pivot=False)\n",
    "        b_permuted = b\n",
    "    \n",
    "    # Forward substitution to solve Ly = b\n",
    "    y = torch.zeros_like(b)\n",
    "    for i in range(n):\n",
    "        y[i] = b_permuted[i]\n",
    "        for j in range(i):\n",
    "            y[i] -= L[i, j] * y[j]\n",
    "        # No need to divide by L[i, i] since it's 1\n",
    "    \n",
    "    # Backward substitution to solve Ux = y\n",
    "    x = torch.zeros_like(y)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] = y[i]\n",
    "        for j in range(i+1, n):\n",
    "            x[i] -= U[i, j] * x[j]\n",
    "        x[i] /= U[i, i]\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Create a right-hand side vector\n",
    "b_3d_small = torch.ones(A_3d_small.shape[0])\n",
    "\n",
    "# Solve the system\n",
    "x_3d_small = solve_with_lu(A_3d_small, b_3d_small)\n",
    "\n",
    "# Verify the solution\n",
    "residual = torch.norm(A_3d_small @ x_3d_small - b_3d_small).item()\n",
    "print(f\"Solution residual: {residual:.2e}\")\n",
    "\n",
    "# Visualize the solution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_3d_small.numpy(), 'o-', markersize=8)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel(\"Grid Point Index\")\n",
    "plt.ylabel(\"Solution Value\")\n",
    "plt.title(\"Solution of 3D Grid Problem\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c290fb4",
   "metadata": {},
   "source": [
    "### Performance Comparison for Large Systems\n",
    "\n",
    "Let's compare the performance of different methods for solving a large linear system:\n",
    "\n",
    "1. LU decomposition with our implementation\n",
    "2. LU decomposition with NumPy/PyTorch\n",
    "3. Direct solve using PyTorch's built-in solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_solving_methods(A, b):\n",
    "    \"\"\"Compare different methods for solving a linear system Ax = b.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    methods = []\n",
    "    times = []\n",
    "    residuals = []\n",
    "    \n",
    "    # Method 1: Our LU implementation\n",
    "    start_time = time.time()\n",
    "    x_our = solve_with_lu(A, b)\n",
    "    times.append(time.time() - start_time)\n",
    "    residuals.append(torch.norm(A @ x_our - b).item())\n",
    "    methods.append(\"Our LU\")\n",
    "    \n",
    "    # Method 2: NumPy's LU\n",
    "    start_time = time.time()\n",
    "    A_np = A.numpy()\n",
    "    b_np = b.numpy()\n",
    "    P, L, U = np.linalg.lu(A_np)\n",
    "    # Forward and backward substitution\n",
    "    y = np.linalg.solve(L, P @ b_np)\n",
    "    x_np = np.linalg.solve(U, y)\n",
    "    times.append(time.time() - start_time)\n",
    "    residuals.append(np.linalg.norm(A_np @ x_np - b_np))\n",
    "    methods.append(\"NumPy LU\")\n",
    "    \n",
    "    # Method 3: PyTorch's direct solve\n",
    "    start_time = time.time()\n",
    "    x_torch = torch.linalg.solve(A, b)\n",
    "    times.append(time.time() - start_time)\n",
    "    residuals.append(torch.norm(A @ x_torch - b).item())\n",
    "    methods.append(\"PyTorch Solve\")\n",
    "    \n",
    "    # Method 4: PyTorch's LU solve\n",
    "    start_time = time.time()\n",
    "    LU, pivots = torch.linalg.lu_factor(A)\n",
    "    x_torch_lu = torch.linalg.lu_solve(LU, pivots, b)\n",
    "    times.append(time.time() - start_time)\n",
    "    residuals.append(torch.norm(A @ x_torch_lu - b).item())\n",
    "    methods.append(\"PyTorch LU\")\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(methods, times)\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.title(\"Solving Time Comparison\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(methods, residuals)\n",
    "    plt.ylabel(\"Residual ||Ax - b||\")\n",
    "    plt.title(\"Solution Accuracy Comparison\")\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the comparison\n",
    "    print(\"Performance Comparison:\")\n",
    "    for method, time_taken, residual in zip(methods, times, residuals):\n",
    "        print(f\"{method}: Time = {time_taken:.4f}s, Residual = {residual:.2e}\")\n",
    "\n",
    "# Create a right-hand side vector for the larger problem\n",
    "b_3d = torch.ones(A_3d.shape[0])\n",
    "\n",
    "# Compare solving methods\n",
    "compare_solving_methods(A_3d, b_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4013c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have explored LU decomposition, a fundamental technique in numerical linear algebra:\n",
    "\n",
    "1. We implemented LU decomposition from scratch and visualized the step-by-step process\n",
    "2. We demonstrated the importance of pivoting for numerical stability\n",
    "3. We compared our implementation with built-in functions\n",
    "4. We showed how to use LU decomposition to solve linear systems\n",
    "5. We examined a practical application with a 3D grid problem\n",
    "\n",
    "LU decomposition has several advantages:\n",
    "\n",
    "- It's efficient for solving multiple linear systems with the same coefficient matrix\n",
    "- It provides insight into the structure of the matrix\n",
    "- It can be used for calculating determinants and matrix inverses\n",
    "\n",
    "However, it also has limitations:\n",
    "\n",
    "- It requires O(n³) operations, which can be prohibitive for very large matrices\n",
    "- For sparse matrices, specialized sparse matrix techniques are often more efficient\n",
    "- Numerical stability requires pivoting, which adds complexity\n",
    "\n",
    "In the next notebook, we'll explore more advanced aspects of LU decomposition and its applications."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
